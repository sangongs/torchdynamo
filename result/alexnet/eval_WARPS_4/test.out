AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
cuda eval  alexnet                            torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:11,676] Step 1: torchdynamo begin tracing
torchdynamo.eval_frame: [DEBUG] [2022-10-11 17:24:11,677] skipping __init__ /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/contextlib.py
torchdynamo.eval_frame: [DEBUG] [2022-10-11 17:24:11,677] skipping __enter__ /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/contextlib.py
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,730] TRACE starts_line benchmarks/torchbench.py:355
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,730] TRACE LOAD_FAST mod []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,730] TRACE LOAD_FAST inputs [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,730] TRACE CALL_FUNCTION_EX 0 [NNModuleVariable(), ListVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,734] INLINING <code object forward at 0x7ff2cdf6ba80, file "/fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py", line 47> 
  48           0 LOAD_FAST                0 (self)
              2 LOAD_METHOD              0 (features)
              4 LOAD_FAST                1 (x)
              6 CALL_METHOD              1
              8 STORE_FAST               1 (x)

 49          10 LOAD_FAST                0 (self)
             12 LOAD_METHOD              1 (avgpool)
             14 LOAD_FAST                1 (x)
             16 CALL_METHOD              1
             18 STORE_FAST               1 (x)

 50          20 LOAD_GLOBAL              2 (torch)
             22 LOAD_METHOD              3 (flatten)
             24 LOAD_FAST                1 (x)
             26 LOAD_CONST               1 (1)
             28 CALL_METHOD              2
             30 STORE_FAST               1 (x)

 51          32 LOAD_FAST                0 (self)
             34 LOAD_METHOD              4 (classifier)
             36 LOAD_FAST                1 (x)
             38 CALL_METHOD              1
             40 STORE_FAST               1 (x)

 52          42 LOAD_FAST                1 (x)
             44 RETURN_VALUE
 

torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,737] TRACE starts_line /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py:48
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,737] TRACE LOAD_FAST self []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,737] TRACE LOAD_ATTR features [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,743] TRACE LOAD_FAST x [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,743] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,768] TRACE STORE_FAST x [TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,769] TRACE starts_line /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py:49
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,769] TRACE LOAD_FAST self []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,769] TRACE LOAD_ATTR avgpool [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,772] TRACE LOAD_FAST x [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,772] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,777] TRACE STORE_FAST x [TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,777] TRACE starts_line /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py:50
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,778] TRACE LOAD_GLOBAL torch []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,778] TRACE LOAD_ATTR flatten [TorchVariable(<module 'torch' from '/fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torch/__init__.py'>)]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,778] TRACE LOAD_FAST x [TorchVariable(<built-in method flatten of type object at 0x7ff34d809b20>)]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,781] TRACE LOAD_CONST 1 [TorchVariable(<built-in method flatten of type object at 0x7ff34d809b20>), TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,781] TRACE CALL_FUNCTION 2 [TorchVariable(<built-in method flatten of type object at 0x7ff34d809b20>), TensorVariable(), ConstantVariable(int)]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,788] TRACE STORE_FAST x [TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,788] TRACE starts_line /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py:51
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,789] TRACE LOAD_FAST self []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,789] TRACE LOAD_ATTR classifier [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,794] TRACE LOAD_FAST x [NNModuleVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,794] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,808] TRACE STORE_FAST x [TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,809] TRACE starts_line /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py:52
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,809] TRACE LOAD_FAST x []
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,809] TRACE RETURN_VALUE None [TensorVariable()]
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,809] DONE INLINING <code object forward at 0x7ff2cdf6ba80, file "/fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/site-packages/torchvision/models/alexnet.py", line 47>
torchdynamo.symbolic_convert: [DEBUG] [2022-10-11 17:24:11,809] TRACE RETURN_VALUE None [TensorVariable()]
torchdynamo.output_graph: [INFO] [2022-10-11 17:24:11,816] Step 2: calling compiler function
torchdynamo.output_graph: [INFO] [2022-10-11 17:24:11,845] Step 2: done compiler function
torchdynamo.output_graph: [Level 15] [2022-10-11 17:24:11,851] TRACED GRAPH
 __compiled_fn_0 <eval_with_key>.4 opcode         name              target                                                      args                    kwargs
-------------  ----------------  ----------------------------------------------------------  ----------------------  --------
placeholder    inputs_0_         inputs_0_                                                   ()                      {}
call_module    mod_features_0    mod_features_0                                              (inputs_0_,)            {}
call_module    mod_features_1    mod_features_1                                              (mod_features_0,)       {}
call_module    mod_features_2    mod_features_2                                              (mod_features_1,)       {}
call_module    mod_features_3    mod_features_3                                              (mod_features_2,)       {}
call_module    mod_features_4    mod_features_4                                              (mod_features_3,)       {}
call_module    mod_features_5    mod_features_5                                              (mod_features_4,)       {}
call_module    mod_features_6    mod_features_6                                              (mod_features_5,)       {}
call_module    mod_features_7    mod_features_7                                              (mod_features_6,)       {}
call_module    mod_features_8    mod_features_8                                              (mod_features_7,)       {}
call_module    mod_features_9    mod_features_9                                              (mod_features_8,)       {}
call_module    mod_features_10   mod_features_10                                             (mod_features_9,)       {}
call_module    mod_features_11   mod_features_11                                             (mod_features_10,)      {}
call_module    mod_features_12   mod_features_12                                             (mod_features_11,)      {}
call_module    mod_avgpool       mod_avgpool                                                 (mod_features_12,)      {}
call_function  flatten           <built-in method flatten of type object at 0x7ff34d809b20>  (mod_avgpool, 1)        {}
call_module    mod_classifier_0  mod_classifier_0                                            (flatten,)              {}
call_module    mod_classifier_1  mod_classifier_1                                            (mod_classifier_0,)     {}
call_module    mod_classifier_2  mod_classifier_2                                            (mod_classifier_1,)     {}
call_module    mod_classifier_3  mod_classifier_3                                            (mod_classifier_2,)     {}
call_module    mod_classifier_4  mod_classifier_4                                            (mod_classifier_3,)     {}
call_module    mod_classifier_5  mod_classifier_5                                            (mod_classifier_4,)     {}
call_module    mod_classifier_6  mod_classifier_6                                            (mod_classifier_5,)     {}
output         output            output                                                      ((mod_classifier_6,),)  {}

torchdynamo.convert_frame: [Level 15] [2022-10-11 17:24:11,852] ORIGINAL BYTECODE forward_pass benchmarks/torchbench.py line 354 
355           0 LOAD_FAST                1 (mod)
              2 LOAD_FAST                2 (inputs)
              4 CALL_FUNCTION_EX         0
              6 RETURN_VALUE

 
torchdynamo.convert_frame: [Level 15] [2022-10-11 17:24:11,855] MODIFIED BYTECODE forward_pass benchmarks/torchbench.py line 354 
354           0 LOAD_GLOBAL              1 (__compiled_fn_0)
              2 LOAD_FAST                2 (inputs)
              4 LOAD_CONST               1 (0)
              6 BINARY_SUBSCR
              8 CALL_FUNCTION            1
             10 UNPACK_SEQUENCE          1
             12 RETURN_VALUE

 
torchdynamo.convert_frame: [Level 15] [2022-10-11 17:24:12,114] GUARDS:
 - 
            local 'mod' NN_MODULE
            {
                'guard_types': ['ID_MATCH'],
                'code': ['___check_obj_id(mod, 140680807424640)'],
                'obj_weakref': <weakref at 0x7ff2cd69be00; to 'AlexNet' at 0x7ff2cd8da280>
                'guarded_class': <weakref at 0x7ff2cdf69680; to 'type' at 0x558f9080a250 (AlexNet)>
            }
            
 - 
            local 'inputs' LIST_LENGTH
            {
                'guard_types': ['LIST_LENGTH'],
                'code': ['___check_type_id(inputs, 94074974225440)', 'len(inputs) == 1'],
                'obj_weakref': None
                'guarded_class': <weakref at 0x7ff36f49fae0; to 'type' at 0x558f896bc420 (list)>
            }
            
 - 
            local 'inputs[0]' TENSOR_MATCH
            {
                'guard_types': ['TENSOR_MATCH'],
                'code': None,
                'obj_weakref': <weakref at 0x7ff2cd79fe00; to 'Tensor' at 0x7ff2cd8bc2c0>
                'guarded_class': <weakref at 0x7ff2f6f6a4a0; to 'torch._C._TensorMeta' at 0x558f8ef8a3b0 (Tensor)>
            }
            
 - 
            global '__import_torchvision_dot_models_dot_alexnet.torch' FUNCTION_MATCH
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.avgpool' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[0]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[1]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[2]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[3]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[4]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[5]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[6]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[7]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[8]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[9]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[10]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[11]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.features[12]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[0]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[1]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[2]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[3]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[4]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[5]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
 - 
            local_nn_module 'mod.classifier[6]' NN_MODULE
            {
                'guard_types': None,
                'code': None,
                'obj_weakref': None
                'guarded_class': None
            }
            
torchdynamo.eval_frame: [DEBUG] [2022-10-11 17:24:12,115] skipping _fn /fsx/users/guoqiang/work/torchdynamo/torchdynamo/eval_frame.py
torchdynamo.eval_frame: [DEBUG] [2022-10-11 17:24:12,117] skipping nothing /fsx/users/guoqiang/work/torchdynamo/torchdynamo/eval_frame.py
torchinductor.compile_fx: [INFO] [2022-10-11 17:24:12,147] Step 3: torchinductor compiling FORWARDS graph 0
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,759] Scheduler.codegen():
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,760] ExternKernelSchedulerNode(name='buf0'): unmet_dependencies = set(), writes = {StarDep(name='buf0')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,762] SchedulerNode(name='buf1'): unmet_dependencies = {MemoryDep(name='buf0', index=c0, size=(198246400,))}, writes = {MemoryDep(name='buf1', index=c0, size=(198246400,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,763] SchedulerNode(name='buf2'): unmet_dependencies = {MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 112, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 57, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 55, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 56, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 110, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 2, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 111, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2, size=(65536, 27, 27)), MemoryDep(name='buf1', index=3025*c0 + 110*c1 + 2*c2 + 1, size=(65536, 27, 27))}, writes = {MemoryDep(name='buf2', index=c0, size=(47775744,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,771] ExternKernelSchedulerNode(name='buf3'): unmet_dependencies = {StarDep(name='buf2')}, writes = {StarDep(name='buf3')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,771] SchedulerNode(name='buf4'): unmet_dependencies = {MemoryDep(name='buf3', index=c0, size=(143327232,))}, writes = {MemoryDep(name='buf4', index=c0, size=(143327232,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,773] SchedulerNode(name='buf5'): unmet_dependencies = {MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 27, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 54, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 29, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 56, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 2, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 55, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 1, size=(196608, 13, 13)), MemoryDep(name='buf4', index=729*c0 + 54*c1 + 2*c2 + 28, size=(196608, 13, 13))}, writes = {MemoryDep(name='buf5', index=c0, size=(33226752,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,779] ExternKernelSchedulerNode(name='buf6'): unmet_dependencies = {StarDep(name='buf5')}, writes = {StarDep(name='buf6')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,779] SchedulerNode(name='buf7'): unmet_dependencies = {MemoryDep(name='buf6', index=c0, size=(66453504,))}, writes = {MemoryDep(name='buf7', index=c0, size=(66453504,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,781] ExternKernelSchedulerNode(name='buf8'): unmet_dependencies = {StarDep(name='buf7')}, writes = {StarDep(name='buf8')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,781] SchedulerNode(name='buf9'): unmet_dependencies = {MemoryDep(name='buf8', index=c0, size=(44302336,))}, writes = {MemoryDep(name='buf9', index=c0, size=(44302336,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,781] ExternKernelSchedulerNode(name='buf10'): unmet_dependencies = {StarDep(name='buf9')}, writes = {StarDep(name='buf10')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,781] SchedulerNode(name='buf11'): unmet_dependencies = {MemoryDep(name='buf10', index=c0, size=(44302336,))}, writes = {MemoryDep(name='buf11', index=c0, size=(44302336,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,782] FusedSchedulerNode(nodes=buf12_buf13): unmet_dependencies = {MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 15, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 26, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 1, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 27, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 2, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 13, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 14, size=(262144, 6, 6)), MemoryDep(name='buf11', index=169*c0 + 26*c1 + 2*c2 + 28, size=(262144, 6, 6))}, writes = {MemoryDep(name='buf12', index=c0, size=(9437184,)), MemoryDep(name='buf13', index=c0, size=(9437184,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,789] ExternKernelSchedulerNode(name='buf14'): unmet_dependencies = {StarDep(name='buf13')}, writes = {StarDep(name='buf14')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,789] SchedulerNode(name='buf15'): unmet_dependencies = {MemoryDep(name='buf14', index=c0, size=(4194304,))}, writes = {MemoryDep(name='buf15', index=c0, size=(4194304,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,789] ExternKernelSchedulerNode(name='buf16'): unmet_dependencies = {StarDep(name='buf15')}, writes = {StarDep(name='buf16')}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,789] SchedulerNode(name='buf17'): unmet_dependencies = {MemoryDep(name='buf16', index=c0, size=(4194304,))}, writes = {MemoryDep(name='buf17', index=c0, size=(4194304,))}
torchinductor.scheduler: [INFO] [2022-10-11 17:24:12,791] ExternKernelSchedulerNode(name='buf18'): unmet_dependencies = {StarDep(name='buf17')}, writes = {StarDep(name='buf18')}
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,795] schedule: [SchedulerNode(name='buf1')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,805] schedule: [SchedulerNode(name='buf2')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,830] schedule: [SchedulerNode(name='buf4')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,838] schedule: [SchedulerNode(name='buf5')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,863] schedule: [SchedulerNode(name='buf7')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,871] schedule: [SchedulerNode(name='buf9')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,879] schedule: [SchedulerNode(name='buf11')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,884] schedule: [SchedulerNode(name='buf12'), SchedulerNode(name='buf13')]
torchinductor.scheduler: [DEBUG] [2022-10-11 17:24:12,906] remove_buffer('buf12')
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,911] schedule: [SchedulerNode(name='buf15')]
torchinductor.codegen.triton: [Level 15] [2022-10-11 17:24:12,916] schedule: [SchedulerNode(name='buf17')]
torchinductor.graph: [Level 15] [2022-10-11 17:24:12,984] Output code: /tmp/torchinductor_guoqiang/2l/c2lji337xtkayeoyyddkcabplourojkasaerpn2myzdihjvvovem.py
torchinductor.compile_fx: [INFO] [2022-10-11 17:24:12,985] Step 3: torchinductor done compiling FORWARDS graph 0
torchdynamo.eval_frame: [DEBUG] [2022-10-11 17:24:13,124] skipping __exit__ /fsx/users/guoqiang/work/torchdynamo/env/lib/python3.8/contextlib.py
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,124] Step 1: torchdynamo done tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,124] Step 1: torchdynamo begin tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,125] Step 1: torchdynamo done tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,128] Step 1: torchdynamo begin tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,130] Step 1: torchdynamo done tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,130] Step 1: torchdynamo begin tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,133] Step 1: torchdynamo done tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,135] Step 1: torchdynamo begin tracing
torchdynamo.eval_frame: [INFO] [2022-10-11 17:24:13,135] Step 1: torchdynamo done tracing
opcode         name                       target                                args                                                                   kwargs
-------------  -------------------------  ------------------------------------  ---------------------------------------------------------------------  --------
placeholder    arg0_1                     arg0_1                                ()                                                                     {}
placeholder    arg1_1                     arg1_1                                ()                                                                     {}
placeholder    arg2_1                     arg2_1                                ()                                                                     {}
placeholder    arg3_1                     arg3_1                                ()                                                                     {}
placeholder    arg4_1                     arg4_1                                ()                                                                     {}
placeholder    arg5_1                     arg5_1                                ()                                                                     {}
placeholder    arg6_1                     arg6_1                                ()                                                                     {}
placeholder    arg7_1                     arg7_1                                ()                                                                     {}
placeholder    arg8_1                     arg8_1                                ()                                                                     {}
placeholder    arg9_1                     arg9_1                                ()                                                                     {}
placeholder    arg10_1                    arg10_1                               ()                                                                     {}
placeholder    arg11_1                    arg11_1                               ()                                                                     {}
placeholder    arg12_1                    arg12_1                               ()                                                                     {}
placeholder    arg13_1                    arg13_1                               ()                                                                     {}
placeholder    arg14_1                    arg14_1                               ()                                                                     {}
placeholder    arg15_1                    arg15_1                               ()                                                                     {}
placeholder    arg16_1                    arg16_1                               ()                                                                     {}
call_function  convolution                aten.convolution.default              (arg16_1, arg0_1, arg1_1, [4, 4], [2, 2], [1, 1], False, [0, 0], 1)    {}
call_function  relu_                      aten.relu_.default                    (convolution,)                                                         {}
call_function  max_pool2d_with_indices    aten.max_pool2d_with_indices.default  (relu_, [3, 3], [2, 2])                                                {}
call_function  getitem                    <built-in function getitem>           (max_pool2d_with_indices, 0)                                           {}
call_function  getitem_1                  <built-in function getitem>           (max_pool2d_with_indices, 1)                                           {}
call_function  convolution_1              aten.convolution.default              (getitem, arg2_1, arg3_1, [1, 1], [2, 2], [1, 1], False, [0, 0], 1)    {}
call_function  relu__1                    aten.relu_.default                    (convolution_1,)                                                       {}
call_function  max_pool2d_with_indices_1  aten.max_pool2d_with_indices.default  (relu__1, [3, 3], [2, 2])                                              {}
call_function  getitem_2                  <built-in function getitem>           (max_pool2d_with_indices_1, 0)                                         {}
call_function  getitem_3                  <built-in function getitem>           (max_pool2d_with_indices_1, 1)                                         {}
call_function  convolution_2              aten.convolution.default              (getitem_2, arg4_1, arg5_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)  {}
call_function  relu__2                    aten.relu_.default                    (convolution_2,)                                                       {}
call_function  convolution_3              aten.convolution.default              (relu__2, arg6_1, arg7_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)    {}
call_function  relu__3                    aten.relu_.default                    (convolution_3,)                                                       {}
call_function  convolution_4              aten.convolution.default              (relu__3, arg8_1, arg9_1, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)    {}
call_function  relu__4                    aten.relu_.default                    (convolution_4,)                                                       {}
call_function  max_pool2d_with_indices_2  aten.max_pool2d_with_indices.default  (relu__4, [3, 3], [2, 2])                                              {}
call_function  getitem_4                  <built-in function getitem>           (max_pool2d_with_indices_2, 0)                                         {}
call_function  getitem_5                  <built-in function getitem>           (max_pool2d_with_indices_2, 1)                                         {}
call_function  _adaptive_avg_pool2d       aten._adaptive_avg_pool2d.default     (getitem_4, [6, 6])                                                    {}
call_function  view                       aten.view.default                     (_adaptive_avg_pool2d, [1024, 9216])                                   {}
call_function  permute                    aten.permute.default                  (arg10_1, [1, 0])                                                      {}
call_function  addmm                      aten.addmm.default                    (arg11_1, view, permute)                                               {}
call_function  relu__5                    aten.relu_.default                    (addmm,)                                                               {}
call_function  permute_1                  aten.permute.default                  (arg12_1, [1, 0])                                                      {}
call_function  addmm_1                    aten.addmm.default                    (arg13_1, relu__5, permute_1)                                          {}
call_function  relu__6                    aten.relu_.default                    (addmm_1,)                                                             {}
call_function  permute_2                  aten.permute.default                  (arg14_1, [1, 0])                                                      {}
call_function  addmm_2                    aten.addmm.default                    (arg15_1, relu__6, permute_2)                                          {}
output         output                     output                                ((addmm_2,),)                                                          {}
==========IR inputs===========
{'arg0_1': TensorBox(StorageBox(
  InputBuffer(name='arg0_1', layout=FixedLayout('cuda', torch.float32, size=[64, 3, 11, 11], stride=[363, 121, 11, 1]))
)), 'arg1_1': TensorBox(StorageBox(
  InputBuffer(name='arg1_1', layout=FixedLayout('cuda', torch.float32, size=[64], stride=[1]))
)), 'arg2_1': TensorBox(StorageBox(
  InputBuffer(name='arg2_1', layout=FixedLayout('cuda', torch.float32, size=[192, 64, 5, 5], stride=[1600, 25, 5, 1]))
)), 'arg3_1': TensorBox(StorageBox(
  InputBuffer(name='arg3_1', layout=FixedLayout('cuda', torch.float32, size=[192], stride=[1]))
)), 'arg4_1': TensorBox(StorageBox(
  InputBuffer(name='arg4_1', layout=FixedLayout('cuda', torch.float32, size=[384, 192, 3, 3], stride=[1728, 9, 3, 1]))
)), 'arg5_1': TensorBox(StorageBox(
  InputBuffer(name='arg5_1', layout=FixedLayout('cuda', torch.float32, size=[384], stride=[1]))
)), 'arg6_1': TensorBox(StorageBox(
  InputBuffer(name='arg6_1', layout=FixedLayout('cuda', torch.float32, size=[256, 384, 3, 3], stride=[3456, 9, 3, 1]))
)), 'arg7_1': TensorBox(StorageBox(
  InputBuffer(name='arg7_1', layout=FixedLayout('cuda', torch.float32, size=[256], stride=[1]))
)), 'arg8_1': TensorBox(StorageBox(
  InputBuffer(name='arg8_1', layout=FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 9, 3, 1]))
)), 'arg9_1': TensorBox(StorageBox(
  InputBuffer(name='arg9_1', layout=FixedLayout('cuda', torch.float32, size=[256], stride=[1]))
)), 'arg10_1': TensorBox(StorageBox(
  InputBuffer(name='arg10_1', layout=FixedLayout('cuda', torch.float32, size=[4096, 9216], stride=[9216, 1]))
)), 'arg11_1': TensorBox(StorageBox(
  InputBuffer(name='arg11_1', layout=FixedLayout('cuda', torch.float32, size=[4096], stride=[1]))
)), 'arg12_1': TensorBox(StorageBox(
  InputBuffer(name='arg12_1', layout=FixedLayout('cuda', torch.float32, size=[4096, 4096], stride=[4096, 1]))
)), 'arg13_1': TensorBox(StorageBox(
  InputBuffer(name='arg13_1', layout=FixedLayout('cuda', torch.float32, size=[4096], stride=[1]))
)), 'arg14_1': TensorBox(StorageBox(
  InputBuffer(name='arg14_1', layout=FixedLayout('cuda', torch.float32, size=[1000, 4096], stride=[4096, 1]))
)), 'arg15_1': TensorBox(StorageBox(
  InputBuffer(name='arg15_1', layout=FixedLayout('cuda', torch.float32, size=[1000], stride=[1]))
)), 'arg16_1': TensorBox(StorageBox(
  InputBuffer(name='arg16_1', layout=FixedLayout('cuda', torch.float32, size=[1024, 3, 224, 224], stride=[150528, 50176, 224, 1]))
))}
==========IR buffers==========
[Convolution(name='buf0', layout=FixedLayout('cuda', torch.float32, size=[1024, 64, 55, 55], stride=[193600, 3025, 55, 1]), inputs=[InputBuffer(name='arg16_1', layout=FixedLayout('cuda', torch.float32, size=[1024, 3, 224, 224], stride=[150528, 50176, 224, 1])), InputBuffer(name='arg0_1', layout=FixedLayout('cuda', torch.float32, size=[64, 3, 11, 11], stride=[363, 121, 11, 1]))], constant_args=(None, (4, 4), (2, 2), (1, 1), False, (0, 0), 1), kwargs={}, output_view=None), ComputedBuffer(name='buf1', layout=FixedLayout('cuda', torch.float32, size=[1024, 64, 55, 55], stride=[193600, 3025, 55, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf0, i3 + 55 * i2 + 3025 * i1 + 193600 * i0) + load(arg1_1, i1)),
  ranges=[1024, 64, 55, 55],
  origins={relu_}
)), ComputedBuffer(name='buf2', layout=FixedLayout('cuda', torch.float32, size=[1024, 64, 27, 27], stride=[46656, 729, 27, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  maximum(load(buf1, 112 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 111 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 110 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 57 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 56 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 55 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 2 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 1 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), load(buf1, 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0))))))))),
  ranges=[1024, 64, 27, 27],
  origins={max_pool2d_with_indices}
)), Convolution(name='buf3', layout=FixedLayout('cuda', torch.float32, size=[1024, 192, 27, 27], stride=[139968, 729, 27, 1]), inputs=[ComputedBuffer(name='buf2', layout=FixedLayout('cuda', torch.float32, size=[1024, 64, 27, 27], stride=[46656, 729, 27, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  maximum(load(buf1, 112 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 111 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 110 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 57 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 56 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 55 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 2 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), maximum(load(buf1, 1 + 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0), load(buf1, 2 * i3 + 110 * i2 + 3025 * i1 + 193600 * i0))))))))),
  ranges=[1024, 64, 27, 27],
  origins={max_pool2d_with_indices}
)), InputBuffer(name='arg2_1', layout=FixedLayout('cuda', torch.float32, size=[192, 64, 5, 5], stride=[1600, 25, 5, 1]))], constant_args=(None, (1, 1), (2, 2), (1, 1), False, (0, 0), 1), kwargs={}, output_view=None), ComputedBuffer(name='buf4', layout=FixedLayout('cuda', torch.float32, size=[1024, 192, 27, 27], stride=[139968, 729, 27, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf3, i3 + 27 * i2 + 729 * i1 + 139968 * i0) + load(arg3_1, i1)),
  ranges=[1024, 192, 27, 27],
  origins={relu__1}
)), ComputedBuffer(name='buf5', layout=FixedLayout('cuda', torch.float32, size=[1024, 192, 13, 13], stride=[32448, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  maximum(load(buf4, 56 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 55 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 54 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 29 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 28 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 27 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 2 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 1 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), load(buf4, 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0))))))))),
  ranges=[1024, 192, 13, 13],
  origins={max_pool2d_with_indices_1}
)), Convolution(name='buf6', layout=FixedLayout('cuda', torch.float32, size=[1024, 384, 13, 13], stride=[64896, 169, 13, 1]), inputs=[ComputedBuffer(name='buf5', layout=FixedLayout('cuda', torch.float32, size=[1024, 192, 13, 13], stride=[32448, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  maximum(load(buf4, 56 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 55 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 54 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 29 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 28 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 27 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 2 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), maximum(load(buf4, 1 + 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0), load(buf4, 2 * i3 + 54 * i2 + 729 * i1 + 139968 * i0))))))))),
  ranges=[1024, 192, 13, 13],
  origins={max_pool2d_with_indices_1}
)), InputBuffer(name='arg4_1', layout=FixedLayout('cuda', torch.float32, size=[384, 192, 3, 3], stride=[1728, 9, 3, 1]))], constant_args=(None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1), kwargs={}, output_view=None), ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.float32, size=[1024, 384, 13, 13], stride=[64896, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf6, i3 + 13 * i2 + 169 * i1 + 64896 * i0) + load(arg5_1, i1)),
  ranges=[1024, 384, 13, 13],
  origins={relu__2}
)), Convolution(name='buf8', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 13, 13], stride=[43264, 169, 13, 1]), inputs=[ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.float32, size=[1024, 384, 13, 13], stride=[64896, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf6, i3 + 13 * i2 + 169 * i1 + 64896 * i0) + load(arg5_1, i1)),
  ranges=[1024, 384, 13, 13],
  origins={relu__2}
)), InputBuffer(name='arg6_1', layout=FixedLayout('cuda', torch.float32, size=[256, 384, 3, 3], stride=[3456, 9, 3, 1]))], constant_args=(None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1), kwargs={}, output_view=None), ComputedBuffer(name='buf9', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 13, 13], stride=[43264, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf8, i3 + 13 * i2 + 169 * i1 + 43264 * i0) + load(arg7_1, i1)),
  ranges=[1024, 256, 13, 13],
  origins={relu__3}
)), Convolution(name='buf10', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 13, 13], stride=[43264, 169, 13, 1]), inputs=[ComputedBuffer(name='buf9', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 13, 13], stride=[43264, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf8, i3 + 13 * i2 + 169 * i1 + 43264 * i0) + load(arg7_1, i1)),
  ranges=[1024, 256, 13, 13],
  origins={relu__3}
)), InputBuffer(name='arg8_1', layout=FixedLayout('cuda', torch.float32, size=[256, 256, 3, 3], stride=[2304, 9, 3, 1]))], constant_args=(None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1), kwargs={}, output_view=None), ComputedBuffer(name='buf11', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 13, 13], stride=[43264, 169, 13, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf10, i3 + 13 * i2 + 169 * i1 + 43264 * i0) + load(arg9_1, i1)),
  ranges=[1024, 256, 13, 13],
  origins={relu__4}
)), ComputedBuffer(name='buf12', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 6, 6], stride=[9216, 36, 6, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  maximum(load(buf11, 28 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 27 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 26 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 15 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 14 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 13 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 2 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), maximum(load(buf11, 1 + 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0), load(buf11, 2 * i3 + 26 * i2 + 169 * i1 + 43264 * i0))))))))),
  ranges=[1024, 256, 6, 6],
  origins={max_pool2d_with_indices_2}
)), ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 6, 6], stride=[9216, 36, 6, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  load(buf12, i3 + 6 * i2 + 36 * i1 + 9216 * i0),
  ranges=[1024, 256, 6, 6],
  origins={_adaptive_avg_pool2d}
)), MatrixMultiplyAdd(name='buf14', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), inputs=[InputBuffer(name='arg11_1', layout=FixedLayout('cuda', torch.float32, size=[4096], stride=[1])), ReinterpretView(
  StorageBox(
    ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.float32, size=[1024, 256, 6, 6], stride=[9216, 36, 6, 1]), data=Pointwise(
      'cuda',
      torch.float32,
      load(buf12, i3 + 6 * i2 + 36 * i1 + 9216 * i0),
      ranges=[1024, 256, 6, 6],
      origins={_adaptive_avg_pool2d}
    ))
  ),
  FixedLayout('cuda', torch.float32, size=(1024, 9216), stride=[9216, 1]),
  origins={addmm}
), ReinterpretView(
  StorageBox(
    InputBuffer(name='arg10_1', layout=FixedLayout('cuda', torch.float32, size=[4096, 9216], stride=[9216, 1]))
  ),
  FixedLayout('cuda', torch.float32, size=[9216, 4096], stride=[1, 9216]),
  origins={permute}
)], constant_args=(), kwargs={'beta': 1, 'alpha': 1}, output_view=None), ComputedBuffer(name='buf15', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf14, i1 + 4096 * i0)),
  ranges=[1024, 4096],
  origins={relu__5}
)), MatrixMultiplyAdd(name='buf16', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), inputs=[InputBuffer(name='arg13_1', layout=FixedLayout('cuda', torch.float32, size=[4096], stride=[1])), ComputedBuffer(name='buf15', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf14, i1 + 4096 * i0)),
  ranges=[1024, 4096],
  origins={relu__5}
)), ReinterpretView(
  StorageBox(
    InputBuffer(name='arg12_1', layout=FixedLayout('cuda', torch.float32, size=[4096, 4096], stride=[4096, 1]))
  ),
  FixedLayout('cuda', torch.float32, size=[4096, 4096], stride=[1, 4096]),
  origins={permute_1}
)], constant_args=(), kwargs={'beta': 1, 'alpha': 1}, output_view=None), ComputedBuffer(name='buf17', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf16, i1 + 4096 * i0)),
  ranges=[1024, 4096],
  origins={relu__6}
)), MatrixMultiplyAdd(name='buf18', layout=FixedLayout('cuda', torch.float32, size=[1024, 1000], stride=[1000, 1]), inputs=[InputBuffer(name='arg15_1', layout=FixedLayout('cuda', torch.float32, size=[1000], stride=[1])), ComputedBuffer(name='buf17', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), data=Pointwise(
  'cuda',
  torch.float32,
  relu(load(buf16, i1 + 4096 * i0)),
  ranges=[1024, 4096],
  origins={relu__6}
)), ReinterpretView(
  StorageBox(
    InputBuffer(name='arg14_1', layout=FixedLayout('cuda', torch.float32, size=[1000, 4096], stride=[4096, 1]))
  ),
  FixedLayout('cuda', torch.float32, size=[4096, 1000], stride=[1, 4096]),
  origins={permute_2}
)], constant_args=(), kwargs={'beta': 1, 'alpha': 1}, output_view=None)]
==========IR outputs============
[StorageBox(
  MatrixMultiplyAdd(
    name=buf18,
    layout=FixedLayout('cuda', torch.float32, size=[1024, 1000], stride=[1000, 1]),
    inputs=[InputBuffer(name='arg15_1', layout=FixedLayout('cuda', torch.float32, size=[1000], stride=[1])), ComputedBuffer(name='buf17', layout=FixedLayout('cuda', torch.float32, size=[1024, 4096], stride=[4096, 1]), data=Pointwise(
      'cuda',
      torch.float32,
      relu(load(buf16, i1 + 4096 * i0)),
      ranges=[1024, 4096],
      origins={relu__6}
    )), ReinterpretView(
      StorageBox(
        InputBuffer(name='arg14_1', layout=FixedLayout('cuda', torch.float32, size=[1000, 4096], stride=[4096, 1]))
      ),
      FixedLayout('cuda', torch.float32, size=[4096, 1000], stride=[1, 4096]),
      origins={permute_2}
    )],
    constant_args=(),
    kwargs={'beta': 1, 'alpha': 1},
    output_view=None,
    origins={addmm_2}
  )
)]

from ctypes import c_void_p, c_long
import torch
import random
from torch import empty_strided, as_strided, device
from torchinductor.codecache import AsyncCompile

aten = torch.ops.aten
async_compile = AsyncCompile()

import triton
import triton.language as tl
from torchinductor.triton_ops.autotune import grid
from torch._C import _cuda_getCurrentRawStream as get_cuda_stream


kernel0 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[268435456], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 198246400
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 3025) % 64
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask)
    tmp2 = tmp0 + tmp1
    tmp3 = tl.maximum(0, tmp2)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)
''')


kernel1 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 47775744
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x0 = xindex % 27
    x1 = (xindex // 27) % 27
    x2 = (xindex // 729)
    x3 = xindex
    tmp0 = tl.load(in_ptr0 + ((2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp2 = tl.load(in_ptr0 + (1 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp7 = tl.load(in_ptr0 + (2 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp12 = tl.load(in_ptr0 + (55 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp17 = tl.load(in_ptr0 + (56 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp22 = tl.load(in_ptr0 + (57 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp27 = tl.load(in_ptr0 + (110 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp32 = tl.load(in_ptr0 + (111 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp37 = tl.load(in_ptr0 + (112 + (2*x0) + (110*x1) + (3025*x2)), xmask)
    tmp1 = (2*x0) + (110*x1)
    tmp3 = 1 + (2*x0) + (110*x1)
    tmp4 = tmp2 > tmp0
    tmp5 = tl.where(tmp4, tmp3, tmp1)
    tmp6 = tl.maximum(tmp2, tmp0)
    tmp8 = 2 + (2*x0) + (110*x1)
    tmp9 = tmp7 > tmp6
    tmp10 = tl.where(tmp9, tmp8, tmp5)
    tmp11 = tl.maximum(tmp7, tmp6)
    tmp13 = 55 + (2*x0) + (110*x1)
    tmp14 = tmp12 > tmp11
    tmp15 = tl.where(tmp14, tmp13, tmp10)
    tmp16 = tl.maximum(tmp12, tmp11)
    tmp18 = 56 + (2*x0) + (110*x1)
    tmp19 = tmp17 > tmp16
    tmp20 = tl.where(tmp19, tmp18, tmp15)
    tmp21 = tl.maximum(tmp17, tmp16)
    tmp23 = 57 + (2*x0) + (110*x1)
    tmp24 = tmp22 > tmp21
    tmp25 = tl.where(tmp24, tmp23, tmp20)
    tmp26 = tl.maximum(tmp22, tmp21)
    tmp28 = 110 + (2*x0) + (110*x1)
    tmp29 = tmp27 > tmp26
    tmp30 = tl.where(tmp29, tmp28, tmp25)
    tmp31 = tl.maximum(tmp27, tmp26)
    tmp33 = 111 + (2*x0) + (110*x1)
    tmp34 = tmp32 > tmp31
    tmp35 = tl.where(tmp34, tmp33, tmp30)
    tmp36 = tl.maximum(tmp32, tmp31)
    tmp38 = 112 + (2*x0) + (110*x1)
    tmp39 = tmp37 > tmp36
    tmp40 = tl.where(tmp39, tmp38, tmp35)
    tmp41 = tl.maximum(tmp37, tmp36)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp41, xmask)
''')


kernel2 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[268435456], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 143327232
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 729) % 192
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask)
    tmp2 = tmp0 + tmp1
    tmp3 = tl.maximum(0, tmp2)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)
''')


kernel3 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[33554432], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 33226752
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x0 = xindex % 13
    x1 = (xindex // 13) % 13
    x2 = (xindex // 169)
    x3 = xindex
    tmp0 = tl.load(in_ptr0 + ((2*x0) + (54*x1) + (729*x2)), xmask)
    tmp2 = tl.load(in_ptr0 + (1 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp7 = tl.load(in_ptr0 + (2 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp12 = tl.load(in_ptr0 + (27 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp17 = tl.load(in_ptr0 + (28 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp22 = tl.load(in_ptr0 + (29 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp27 = tl.load(in_ptr0 + (54 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp32 = tl.load(in_ptr0 + (55 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp37 = tl.load(in_ptr0 + (56 + (2*x0) + (54*x1) + (729*x2)), xmask)
    tmp1 = (2*x0) + (54*x1)
    tmp3 = 1 + (2*x0) + (54*x1)
    tmp4 = tmp2 > tmp0
    tmp5 = tl.where(tmp4, tmp3, tmp1)
    tmp6 = tl.maximum(tmp2, tmp0)
    tmp8 = 2 + (2*x0) + (54*x1)
    tmp9 = tmp7 > tmp6
    tmp10 = tl.where(tmp9, tmp8, tmp5)
    tmp11 = tl.maximum(tmp7, tmp6)
    tmp13 = 27 + (2*x0) + (54*x1)
    tmp14 = tmp12 > tmp11
    tmp15 = tl.where(tmp14, tmp13, tmp10)
    tmp16 = tl.maximum(tmp12, tmp11)
    tmp18 = 28 + (2*x0) + (54*x1)
    tmp19 = tmp17 > tmp16
    tmp20 = tl.where(tmp19, tmp18, tmp15)
    tmp21 = tl.maximum(tmp17, tmp16)
    tmp23 = 29 + (2*x0) + (54*x1)
    tmp24 = tmp22 > tmp21
    tmp25 = tl.where(tmp24, tmp23, tmp20)
    tmp26 = tl.maximum(tmp22, tmp21)
    tmp28 = 54 + (2*x0) + (54*x1)
    tmp29 = tmp27 > tmp26
    tmp30 = tl.where(tmp29, tmp28, tmp25)
    tmp31 = tl.maximum(tmp27, tmp26)
    tmp33 = 55 + (2*x0) + (54*x1)
    tmp34 = tmp32 > tmp31
    tmp35 = tl.where(tmp34, tmp33, tmp30)
    tmp36 = tl.maximum(tmp32, tmp31)
    tmp38 = 56 + (2*x0) + (54*x1)
    tmp39 = tmp37 > tmp36
    tmp40 = tl.where(tmp39, tmp38, tmp35)
    tmp41 = tl.maximum(tmp37, tmp36)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp41, xmask)
''')


kernel4 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 66453504
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 169) % 384
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask)
    tmp2 = tmp0 + tmp1
    tmp3 = tl.maximum(0, tmp2)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)
''')


kernel5 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 44302336
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x3 = xindex
    x1 = (xindex // 169) % 256
    tmp0 = tl.load(in_ptr0 + (x3), xmask)
    tmp1 = tl.load(in_ptr1 + (x1), xmask)
    tmp2 = tmp0 + tmp1
    tmp3 = tl.maximum(0, tmp2)
    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)
''')


kernel6 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
    xnumel = 9437184
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x0 = xindex % 6
    x1 = (xindex // 6) % 6
    x2 = (xindex // 36)
    x3 = xindex
    tmp0 = tl.load(in_ptr0 + ((2*x0) + (26*x1) + (169*x2)), xmask)
    tmp2 = tl.load(in_ptr0 + (1 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp7 = tl.load(in_ptr0 + (2 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp12 = tl.load(in_ptr0 + (13 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp17 = tl.load(in_ptr0 + (14 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp22 = tl.load(in_ptr0 + (15 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp27 = tl.load(in_ptr0 + (26 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp32 = tl.load(in_ptr0 + (27 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp37 = tl.load(in_ptr0 + (28 + (2*x0) + (26*x1) + (169*x2)), xmask)
    tmp1 = (2*x0) + (26*x1)
    tmp3 = 1 + (2*x0) + (26*x1)
    tmp4 = tmp2 > tmp0
    tmp5 = tl.where(tmp4, tmp3, tmp1)
    tmp6 = tl.maximum(tmp2, tmp0)
    tmp8 = 2 + (2*x0) + (26*x1)
    tmp9 = tmp7 > tmp6
    tmp10 = tl.where(tmp9, tmp8, tmp5)
    tmp11 = tl.maximum(tmp7, tmp6)
    tmp13 = 13 + (2*x0) + (26*x1)
    tmp14 = tmp12 > tmp11
    tmp15 = tl.where(tmp14, tmp13, tmp10)
    tmp16 = tl.maximum(tmp12, tmp11)
    tmp18 = 14 + (2*x0) + (26*x1)
    tmp19 = tmp17 > tmp16
    tmp20 = tl.where(tmp19, tmp18, tmp15)
    tmp21 = tl.maximum(tmp17, tmp16)
    tmp23 = 15 + (2*x0) + (26*x1)
    tmp24 = tmp22 > tmp21
    tmp25 = tl.where(tmp24, tmp23, tmp20)
    tmp26 = tl.maximum(tmp22, tmp21)
    tmp28 = 26 + (2*x0) + (26*x1)
    tmp29 = tmp27 > tmp26
    tmp30 = tl.where(tmp29, tmp28, tmp25)
    tmp31 = tl.maximum(tmp27, tmp26)
    tmp33 = 27 + (2*x0) + (26*x1)
    tmp34 = tmp32 > tmp31
    tmp35 = tl.where(tmp34, tmp33, tmp30)
    tmp36 = tl.maximum(tmp32, tmp31)
    tmp38 = 28 + (2*x0) + (26*x1)
    tmp39 = tmp37 > tmp36
    tmp40 = tl.where(tmp39, tmp38, tmp35)
    tmp41 = tl.maximum(tmp37, tmp36)
    tl.store(out_ptr1 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp41, xmask)
''')


kernel7 = async_compile.triton('''
import triton
import triton.language as tl
from torchinductor.ir import ReductionHint
from torchinductor.triton_ops.autotune import pointwise
from torchinductor.utils import instance_descriptor

@pointwise(size_hints=[4194304], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())], 'constants': {}})
@triton.jit
def kernel(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
    xnumel = 4194304
    xoffset = tl.program_id(0) * XBLOCK
    xindex = xoffset + tl.reshape(tl.arange(0, XBLOCK), [XBLOCK])
    xmask = xindex < xnumel
    x0 = xindex
    tmp0 = tl.load(in_ptr0 + (x0), xmask)
    tmp1 = tl.maximum(0, tmp0)
    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)
''')


async_compile.wait(globals())
del async_compile

def call(arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1):
    buf0 = aten.convolution(arg16_1, arg0_1, None, (4, 4), (2, 2), (1, 1), False, (0, 0), 1)
    assert buf0.size() == (1024, 64, 55, 55)
    assert buf0.stride() == (193600, 3025, 55, 1)
    buf1 = empty_strided((1024, 64, 55, 55), (193600, 3025, 55, 1), device='cuda', dtype=torch.float32)
    stream0 = get_cuda_stream(0)
    kernel0.run(buf0, arg1_1, buf1, 198246400, grid=grid(198246400), stream=stream0)
    del buf0
    buf2 = empty_strided((1024, 64, 27, 27), (46656, 729, 27, 1), device='cuda', dtype=torch.float32)
    kernel1.run(buf1, buf2, 47775744, grid=grid(47775744), stream=stream0)
    del buf1
    buf3 = aten.convolution(buf2, arg2_1, None, (1, 1), (2, 2), (1, 1), False, (0, 0), 1)
    assert buf3.size() == (1024, 192, 27, 27)
    assert buf3.stride() == (139968, 729, 27, 1)
    del buf2
    buf4 = empty_strided((1024, 192, 27, 27), (139968, 729, 27, 1), device='cuda', dtype=torch.float32)
    kernel2.run(buf3, arg3_1, buf4, 143327232, grid=grid(143327232), stream=stream0)
    del buf3
    buf5 = empty_strided((1024, 192, 13, 13), (32448, 169, 13, 1), device='cuda', dtype=torch.float32)
    kernel3.run(buf4, buf5, 33226752, grid=grid(33226752), stream=stream0)
    del buf4
    buf6 = aten.convolution(buf5, arg4_1, None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1)
    assert buf6.size() == (1024, 384, 13, 13)
    assert buf6.stride() == (64896, 169, 13, 1)
    del buf5
    buf7 = empty_strided((1024, 384, 13, 13), (64896, 169, 13, 1), device='cuda', dtype=torch.float32)
    kernel4.run(buf6, arg5_1, buf7, 66453504, grid=grid(66453504), stream=stream0)
    del buf6
    buf8 = aten.convolution(buf7, arg6_1, None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1)
    assert buf8.size() == (1024, 256, 13, 13)
    assert buf8.stride() == (43264, 169, 13, 1)
    del buf7
    buf9 = empty_strided((1024, 256, 13, 13), (43264, 169, 13, 1), device='cuda', dtype=torch.float32)
    kernel5.run(buf8, arg7_1, buf9, 44302336, grid=grid(44302336), stream=stream0)
    del buf8
    buf10 = aten.convolution(buf9, arg8_1, None, (1, 1), (1, 1), (1, 1), False, (0, 0), 1)
    assert buf10.size() == (1024, 256, 13, 13)
    assert buf10.stride() == (43264, 169, 13, 1)
    buf11 = buf9; del buf9  # reuse
    kernel5.run(buf10, arg9_1, buf11, 44302336, grid=grid(44302336), stream=stream0)
    del buf10
    buf13 = empty_strided((1024, 256, 6, 6), (9216, 36, 6, 1), device='cuda', dtype=torch.float32)
    kernel6.run(buf11, buf13, 9437184, grid=grid(9437184), stream=stream0)
    del buf11
    buf14 = empty_strided((1024, 4096), (4096, 1), device='cuda', dtype=torch.float32)
    aten.addmm.out(arg11_1, as_strided(buf13, (1024, 9216), (9216, 1)), as_strided(arg10_1, (9216, 4096), (1, 9216)), beta=1, alpha=1, out=buf14)
    del buf13
    buf15 = empty_strided((1024, 4096), (4096, 1), device='cuda', dtype=torch.float32)
    kernel7.run(buf14, buf15, 4194304, grid=grid(4194304), stream=stream0)
    buf16 = buf14; del buf14  # reuse
    aten.addmm.out(arg13_1, buf15, as_strided(arg12_1, (4096, 4096), (1, 4096)), beta=1, alpha=1, out=buf16)
    buf17 = buf15; del buf15  # reuse
    kernel7.run(buf16, buf17, 4194304, grid=grid(4194304), stream=stream0)
    del buf16
    buf18 = empty_strided((1024, 1000), (1000, 1), device='cuda', dtype=torch.float32)
    aten.addmm.out(arg15_1, buf17, as_strided(arg14_1, (4096, 1000), (1, 4096)), beta=1, alpha=1, out=buf18)
    return (buf18, )


if __name__ == "__main__":
    from torchdynamo.testing import rand_strided
    from torchinductor.utils import print_performance
    arg0_1 = rand_strided((64, 3, 11, 11), (363, 121, 11, 1), device='cuda', dtype=torch.float32)
    arg1_1 = rand_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
    arg2_1 = rand_strided((192, 64, 5, 5), (1600, 25, 5, 1), device='cuda', dtype=torch.float32)
    arg3_1 = rand_strided((192, ), (1, ), device='cuda', dtype=torch.float32)
    arg4_1 = rand_strided((384, 192, 3, 3), (1728, 9, 3, 1), device='cuda', dtype=torch.float32)
    arg5_1 = rand_strided((384, ), (1, ), device='cuda', dtype=torch.float32)
    arg6_1 = rand_strided((256, 384, 3, 3), (3456, 9, 3, 1), device='cuda', dtype=torch.float32)
    arg7_1 = rand_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
    arg8_1 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda', dtype=torch.float32)
    arg9_1 = rand_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
    arg10_1 = rand_strided((4096, 9216), (9216, 1), device='cuda', dtype=torch.float32)
    arg11_1 = rand_strided((4096, ), (1, ), device='cuda', dtype=torch.float32)
    arg12_1 = rand_strided((4096, 4096), (4096, 1), device='cuda', dtype=torch.float32)
    arg13_1 = rand_strided((4096, ), (1, ), device='cuda', dtype=torch.float32)
    arg14_1 = rand_strided((1000, 4096), (4096, 1), device='cuda', dtype=torch.float32)
    arg15_1 = rand_strided((1000, ), (1, ), device='cuda', dtype=torch.float32)
    arg16_1 = rand_strided((1024, 3, 224, 224), (150528, 50176, 224, 1), device='cuda', dtype=torch.float32)
    print_performance(lambda: call(arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1))

1.154x p=0.00
